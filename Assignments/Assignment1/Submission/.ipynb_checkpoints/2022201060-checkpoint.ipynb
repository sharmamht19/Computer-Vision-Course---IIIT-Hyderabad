{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ec9d02",
   "metadata": {},
   "source": [
    "## Assignment Number : 1\n",
    "### Name : MOHIT SHARMA\n",
    "### Roll Number : 2022201060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80b7dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e5756",
   "metadata": {},
   "source": [
    "# Q1: Own Calibration:\n",
    "\n",
    "## 1. For the given image `calib-object.jpg`, identify the chessboard internal corners. You may use external libraries to detect the chessboard corners. Note, each square of the chess board is 2cm Ã— 2cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f904e531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.218] global loadsave.cpp:248 findDecoder imread_('calib-object.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalib-object.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m max_corners \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m140\u001b[39m\n\u001b[1;32m      4\u001b[0m quality \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.275\u001b[39m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread('calib-object.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "max_corners = 140\n",
    "quality = 0.275\n",
    "Ecl_dist = 130\n",
    "corners = cv.goodFeaturesToTrack(gray, max_corners, quality ,Ecl_dist)\n",
    "corners = np.int0(corners)\n",
    "print(corners.shape)\n",
    "#print(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e36692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show corners in image \n",
    "def show_corners(img , corners, shiftx = 25, shifty = - 25,bold = 3,R = 100,G = 155,B = 100,font_size = 0.7):\n",
    "#     print(img)\n",
    "#     print(corners)\n",
    "    plt.figure(figsize=(12, 15))  \n",
    "    for index, corner in enumerate(corners):\n",
    "        point = (corner.ravel())\n",
    "#         print(point)\n",
    "        cv.circle(img, point, 10, (0, 255, 0), -1)  \n",
    "        cv.putText(img, f'{index}: {point}', (point[0] + shiftx, point[1] + shifty), cv.FONT_HERSHEY_SIMPLEX, font_size, (R, G, B), bold, cv.LINE_AA)\n",
    "    \n",
    "    plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149629ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_corners(img , corners)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9163e9b",
   "metadata": {},
   "source": [
    "## 2.  Implement the camera calibration process discussed in the lecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007b5764",
   "metadata": {},
   "source": [
    "##### Assume a world origin, create a set of corresponding points in the world coordinate and image plane, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78a44a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pixel_coordinates = np.array([corners[13][0],corners[73][0],corners[0][0], corners[99][0],corners[79][0], corners[81][0], corners[108][0], corners[55][0],corners[34][0], corners[18][0]])\n",
    "world_coordinates = np.array([[14,0,0],[14,18,0],[0,16,0],[2, 16, 0],[0,18,14], [0, 10, 4], [0, 2, 8], [0, 10, 10],[6, 2, 0], [12, 6, 0]])\n",
    "\n",
    "for idx, (world_coord, pixel_coord) in enumerate(zip(world_coordinates, pixel_coordinates)):\n",
    "    print(f\"World Coordinate {idx + 1}: ({world_coord[0]}, {world_coord[1]}, {world_coord[2]}) -> Pixel Coordinate: ({pixel_coord[0]}, {pixel_coord[1]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb553350",
   "metadata": {},
   "source": [
    "#### Compute both extrinsics (translation vector, rotation matrix) and intrinsics (assume no skew) without using any external libraries for the calib-object.jpg image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd6ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_calibration_results(camera_matrix, rotation_matrix, translation_vector, projection_matrix):\n",
    "    \n",
    "    print(\"Camera Calibration Results:\")\n",
    "    print(\"============================\\n\")\n",
    "\n",
    "    print(\"Camera Matrix (Intrinsic Matrix):\")\n",
    "    print(\"----------------------------------\")\n",
    "    print(camera_matrix)\n",
    "\n",
    "    print(\"\\nRotation Matrix:\")\n",
    "    print(\"-----------------\")\n",
    "    print(rotation_matrix)\n",
    "\n",
    "    print(\"\\nTranslation Vector:\")\n",
    "    print(\"--------------------\")\n",
    "    print(translation_vector)\n",
    "\n",
    "    print(\"\\nProjection Matrix (Camera Calibration Matrix):\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(projection_matrix)\n",
    "\n",
    "def dlt_method(world_coordinates, image_coordinates):\n",
    "    n = len(world_coordinates)\n",
    "    Amatrix = np.zeros((2 * n, 12))\n",
    "\n",
    "    for i in range(n):\n",
    "        X, Y, Z = world_coordinates[i]\n",
    "        u, v = image_coordinates[i]\n",
    "        Amatrix[2 * i] = [X, Y, Z, 1, 0, 0, 0, 0, -u * X, -u * Y, -u * Z, -u]\n",
    "        Amatrix[2 * i + 1] = [0, 0, 0, 0, X, Y, Z, 1, -v * X, -v * Y, -v * Z, -v]\n",
    "        \n",
    "    _, _, V = np.linalg.svd(Amatrix)\n",
    "    Projection_matrix = V[-1].reshape(3, 4)\n",
    "    return Projection_matrix\n",
    "\n",
    "def extract_parameters(projection_matrix):\n",
    "    \n",
    "    # Extract intrinsic matrix K and translation vector C from the projection matrix\n",
    "    K_R = projection_matrix[:, 0:3]\n",
    "    K_R_C = projection_matrix[:, 3]\n",
    "\n",
    "    # Perform QR decomposition of the inverse of KR to obtain rotation matrix Q and upper triangular matrix R\n",
    "    Q, R = np.linalg.qr(np.linalg.inv(K_R))\n",
    "    \n",
    "    # Extract rotation matrix vector T\n",
    "    rotation_matrix = Q.T\n",
    "    # Extract translation vector T\n",
    "    translation_vector = -np.dot(np.linalg.inv(K_R), K_R_C)\n",
    "    \n",
    "    # Intrinsic matrix is the inverse of R normalized such that K[2, 2] = 1\n",
    "    intrinsic_matrix = np.linalg.inv(R)\n",
    "    intrinsic_matrix /= intrinsic_matrix[2, 2]\n",
    "   \n",
    "    # Ensuring correct scaling of K\n",
    "    if intrinsic_matrix[0, 0] > 0:\n",
    "        intrinsic_matrix *= -1\n",
    "        \n",
    "    return intrinsic_matrix, rotation_matrix, translation_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute projection matrix using Direct Linear Transformation (DLT) method\n",
    "projection_matrix = dlt_method(world_coordinates, pixel_coordinates)\n",
    "\n",
    "# Extract intrinsic matrix (camera matrix), rotation matrix, and translation vector from projection matrix\n",
    "camera_matrix, rotation_matrix, translation_vector = extract_parameters(projection_matrix)\n",
    "\n",
    "#print output....\n",
    "print_calibration_results(camera_matrix, rotation_matrix, translation_vector, projection_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5cbc72",
   "metadata": {},
   "source": [
    "## 3. Use the real-world measurements along with the estimated camera parameters to compute the image of a wireframe of the object (Hint: the wireframe is the outer corners of the actual chessboard pattern and has 6 points). Note that you should compute the location of image points as xi = PXi, where P is the projection matrix computed above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pixel_coordinate(projection_matrix, world_coordinate):\n",
    "    # make it homogeneous\n",
    "    world_coordinate = np.append(world_coordinate, 1)\n",
    "    \n",
    "    homogeneous_pixel_coordinate = np.dot(projection_matrix, world_coordinate)\n",
    "    u = homogeneous_pixel_coordinate[0] / homogeneous_pixel_coordinate[2]\n",
    "    v = homogeneous_pixel_coordinate[1] / homogeneous_pixel_coordinate[2]\n",
    "    \n",
    "    return u, v\n",
    "\n",
    "def get_pixel_coordinates(projection_matrix, world_coordinates):\n",
    "    pixel_coordinates =[]\n",
    "    for world_co in world_coordinates:\n",
    "        pixel_co = compute_pixel_coordinate(projection_matrix, world_co)\n",
    "        pixel_coordinates.append(pixel_co)\n",
    "\n",
    "    pixel_coordinates = np.array(pixel_coordinates)\n",
    "    return pixel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d773424",
   "metadata": {},
   "outputs": [],
   "source": [
    "wireframes_world_coordinates = np.array([[0,0,0],[14,0,0],[14,18,0],[0,18,0],[0,18,14],[0,0,14]])\n",
    "wireframes_pixel_coordinates = get_pixel_coordinates(projection_matrix, wireframes_world_coordinates)\n",
    "print(wireframes_pixel_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597c0d9",
   "metadata": {},
   "source": [
    "### Overlay (draw) the wireframe over the actual image of the object using straight lines between the computed points xi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_wireframe(image_path, pixel_coordinates, line_indices, circle_radius=15, circle_color=(0, 255, 0), text_color=(100, 20, 255), line_color=(50, 255, 50), line_thickness=5):\n",
    "    # Load the image\n",
    "    image = cv.imread(image_path)\n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    \n",
    "    for start_idx, end_idx in line_indices:\n",
    "        start_point = tuple(map(int, pixel_coordinates[start_idx]))\n",
    "        end_point = tuple(map(int, pixel_coordinates[end_idx]))\n",
    "        cv.line(image, start_point, end_point, line_color, line_thickness)  \n",
    "    \n",
    "    for idx, point in enumerate(pixel_coordinates):\n",
    "        x, y = map(int, point)\n",
    "        cv.circle(image, (x, y), circle_radius, circle_color, -1)  \n",
    "        cv.putText(image, f'{idx}: ({x}, {y})', (x + 5, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2, cv.LINE_AA)\n",
    " \n",
    "    plt.imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2894750",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "img_path = 'calib-object.jpg'\n",
    "line_indices = [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 0)]\n",
    "visualize_wireframe(img_path, wireframes_pixel_coordinates, line_indices, circle_color=(144, 238, 144), text_color=(128, 128, 128), line_color=(0, 0, 139))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d98a93",
   "metadata": {},
   "source": [
    " ### --> What do you observe about the overlay?\n",
    "\n",
    "The wireframe overlay shows perfect alignment with the world coordinate of chessboard for three outer lines. This indicates that the computed points closely match the chessboard in the image, suggesting accurate calibration and wireframe generation.\n",
    "\n",
    "While not perfect, the alignment of the wireframe overlay with the world coordinate of chessboard is very close for the remaining three lines. There are `slight discrepancies`, but they are minor and do not significantly impact the overall alignment between the wireframe and the object.\n",
    "\n",
    "Throughout the wireframe overlay, consistent distortion is observed, particularly towards the edges of the image. This distortion results in slight deviations or curvatures in the wireframe lines compared to the actual chessboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c866c44",
   "metadata": {},
   "source": [
    "## 4.   Given the rotation matrix, compute the three rotation angles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9e95cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix_to_euler_angles(rotation_matrix):\n",
    "    pitch = np.arctan2(-rotation_matrix[2, 0], np.sqrt(rotation_matrix[0, 0] ** 2 + rotation_matrix[1, 0] ** 2))\n",
    "    roll = np.arctan2(rotation_matrix[2, 1], rotation_matrix[2, 2])\n",
    "    pan = np.arctan2(rotation_matrix[1, 0], rotation_matrix[0, 0])\n",
    "    return pitch, roll, pan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a60b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch, roll, pan = rotation_matrix_to_euler_angles(rotation_matrix)\n",
    "pitch = np.degrees(pitch)\n",
    "roll = np.degrees(roll)\n",
    "pan = np.degrees(pan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87287f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pitch :\", pitch , \"Deg\")\n",
    "print(\"Roll :\", roll , \"Deg\")\n",
    "print(\"Pan :\", pan , \"Deg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf07ab8",
   "metadata": {},
   "source": [
    "## Explain the values that you obtain in terms of pan, tilt, and roll?\n",
    "### Explaination :\n",
    "\n",
    "- **Pitch**: Pitch refers to the up-down movement or tilt of the object or camera. In this case, the pitch is approximately ``-44.05 degrees``, indicating a slight tilt upwards which nearby observed.\n",
    "  \n",
    "- **Roll**: This describes the side-to-side rotation of the object or camera. here, the roll is approximately ``-20.25 degrees``, suggesting a slight counter-clockwise rotation which expected.\n",
    "  \n",
    "- **pan**: This describing the left-right movement of the object or camera. In your case, the pan is approximately ``-165.53 degrees``, indicating a significant counter-clockwise rotation or leftward movement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f4ee5",
   "metadata": {},
   "source": [
    "# Q2: OpenCV Calibration\n",
    "\n",
    "## 1.  Now repeat the camera calibration process for calib-object.jpg using OpenCV calibration func- tions, continue to assume that there is no skew or distortion (Hint: see calibrateCamera() FLAGS). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2773567",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_coordinates = np.array([corners[16][0], corners[18][0],corners[111][0], corners[99][0],corners[34][0],corners[21][0],corners[52][0],corners[40][0]], dtype=np.float32)\n",
    "world_coordinates = np.array([[2,6,0], [12, 6, 0],[10,4,0], [2, 16, 0],[6, 2, 0],[8,2,0],[8,16,0],[4,12,0]],dtype=np.float32)\n",
    "\n",
    "height, width = gray.shape[:2]\n",
    "imageSize = (width, height)\n",
    "retval, camera_matrix, dist_coeffs, rvecs, tvecs = cv.calibrateCamera([world_coordinates], [pixel_coordinates], imageSize, None, None)\n",
    "\n",
    "R, _ = cv.Rodrigues(rvecs[0])\n",
    "opencv_projection_matrix = np.dot(camera_matrix, np.hstack((R, tvecs[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2577dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print reprojection error\n",
    "print(f\"\\nReprojection error (retval): {retval}\")\n",
    "\n",
    "# Print camera matrix\n",
    "print(\"\\nCamera matrix:\")\n",
    "print(camera_matrix)\n",
    "\n",
    "# Print distortion coefficients\n",
    "print(\"\\nDistortion coefficients:\")\n",
    "print(dist_coeffs)\n",
    "\n",
    "# Print rotation vectors\n",
    "print(\"\\nAll rvecs:\")\n",
    "for idx, rvec in enumerate(rvecs):\n",
    "    print(f\"Rotation vector {idx + 1}:\")\n",
    "    print(rvec)\n",
    "\n",
    "# Print translation vectors\n",
    "print(\"\\nAll tvecs:\")\n",
    "for idx, tvec in enumerate(tvecs):\n",
    "    print(f\"Translation vector {idx + 1}:\")\n",
    "    print(tvec)\n",
    "\n",
    "    \n",
    "print(\"\\nProjection Matrix:\")\n",
    "print(opencv_projection_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ea598",
   "metadata": {},
   "outputs": [],
   "source": [
    "opencv_wireframes_world_coordinates = np.array([[0,0,0],[14,0,0],[14,18,0],[0,18,0],[0,18,-14],[0,0,-14]])\n",
    "opencv_wireframes_pixel_coordinates = get_pixel_coordinates(opencv_projection_matrix, opencv_wireframes_world_coordinates)\n",
    "\n",
    "# visualize wireframe\n",
    "visualize_wireframe(img_path, opencv_wireframes_pixel_coordinates, line_indices,circle_color=(144, 238, 144), text_color=(128, 128, 128), line_color=(0, 0, 139))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff742758",
   "metadata": {},
   "source": [
    "### Q. - > How does your result compare with Q1 above? Repeat the overlay of the wireframe using the new parameters. Describe your observations.\n",
    "\n",
    "When comparing the results obtained from the opencv's calibrateCamera() with those from the own calibration process described observations are :\n",
    "\n",
    "   - In opencv's calibrateCamera() results, there are some differences in the alignment between the wireframe overlay and the chessboard object in the image compared to the previous results.\n",
    "   \n",
    "   - After repeating the overlay of the wireframe using the opencv's calibrateCamera() parameters, we can observe that more lines of the wireframe do not perfectly align with the object compared to the previous calibration also we can see little distortion of points in the image. \n",
    "\n",
    "   - The opencv's calibrateCamera() parameters results in a slightly different projection matrix, affecting the accuracy of the wireframe overlay. This may be leading to discrepancies between the wireframe and the chessboard in the image.\n",
    "   \n",
    "   - While both calibration processes aim to accurately map the 3D world coordinates to 2D image coordinates, variations in the calibration parameters may result in differences in the alignment and accuracy of the wireframe overlay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586fa6d",
   "metadata": {},
   "source": [
    "## 2.  Repeat Q2.1, for the second image assign1.jpg. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdedc1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "objp = np.zeros((5*5, 3), np.float32)\n",
    "grid_size = 5  # Grid size for x and y coordinates\n",
    "\n",
    "for i in range(1, grid_size + 1):\n",
    "    for j in range(1, grid_size + 1):\n",
    "        objp[(i - 1) * grid_size + (j - 1)] = [i*2, j*2, 0]\n",
    "\n",
    "objpoints = [] \n",
    "imgpoints = [] \n",
    "img_new_name  = \"assign1.jpg\"\n",
    "\n",
    "img = cv.imread(img_new_name)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "retVal, corners = cv.findChessboardCorners(gray, (5,5), None)\n",
    "\n",
    "if retVal == True:\n",
    "    objpoints.append(objp)\n",
    "    corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "    imgpoints.append(corners2)\n",
    "    corners = np.int0(corners)\n",
    "    show_corners(img , corners, shiftx = 0, shifty = 20,bold = 1,R = 0,G = 0,B = 0,font_size = 0.4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f99aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "objpoints = np.array(objpoints,dtype=np.float32)\n",
    "imgpoints = np.array(imgpoints, dtype=np.float32)\n",
    "new_imageSize = gray.shape[::-1]\n",
    "imgpoints = imgpoints.reshape((1, 25, 2))\n",
    "new_retval, new_camera_matrix, new_dist_coeffs, new_rvecs, new_tvecs = cv.calibrateCamera(objpoints, imgpoints, new_imageSize, None, None)\n",
    "new_R, _ = cv.Rodrigues(new_rvecs[0])\n",
    "new_projection_matrix = np.dot(new_camera_matrix, np.hstack((new_R, new_tvecs[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c530a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of objpoints and imgpoints\n",
    "print(\"Object points shape:\", objpoints.shape)\n",
    "print(\"\\n Image points shape:\", imgpoints.shape)\n",
    "\n",
    "# Print the lengths of objpoints and imgpoints\n",
    "print(\"\\n Number of object points:\", len(objpoints[0]))\n",
    "print(\"\\n Number of image points:\", len(imgpoints[0]))\n",
    "\n",
    "\n",
    "# Print projection matrix\n",
    "print(\"\\n Projection Matrix:\\n\", new_projection_matrix)\n",
    "\n",
    "# Print corresponding object and image points\n",
    "print(\"\\n Corresponding object and image points:\")\n",
    "for obj_point, img_point in zip(objpoints[0], imgpoints[0]):\n",
    "    print(f\"Object point: {obj_point} --> Image point: {img_point}\")\n",
    "\n",
    "# Print reprojection error\n",
    "print(\"\\n Reprojection error (retval):\", new_retval)\n",
    "\n",
    "# Print camera matrix and distortion coefficients\n",
    "print(\"\\n Camera matrix:\\n\", new_camera_matrix)\n",
    "print(\"\\n Distortion coefficients:\\n\", new_dist_coeffs)\n",
    "\n",
    "# Print rotation and translation vectors\n",
    "print(\"\\n All rvecs: \\n\", new_rvecs)\n",
    "print(\"\\n All tvecs: \\n\", new_tvecs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wireframes_world_coordinates = np.array([[0,0,0],[12,0,0],[0,12,0],[12,12,0]])\n",
    "new_line_indices = [(0, 2), (2, 3), (3, 1), (1, 0)]\n",
    "new_wireframes_pixel_coordinates = get_pixel_coordinates(new_projection_matrix, new_wireframes_world_coordinates)\n",
    "\n",
    "# visualize wireframe\n",
    "visualize_wireframe(img_new_name, new_wireframes_pixel_coordinates, new_line_indices,circle_color=(144, 238, 144), text_color=(128, 128, 128), line_color=(0, 0, 139))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c56ae90",
   "metadata": {},
   "source": [
    "### Q. Does the wireframe overlay show significant distor- tions? Comment. What can we say about the computed projection matrix when trying to do calibration based on world coordinate points that are co-planar? (Hint: we looked at co-planar points in two-view geometry).\n",
    "\n",
    "- In this case, when using the `cv2.calibrateCamera()` function on a different image containing a planar chessboard of size 6x6, the wireframe overlay shows no significant distortions. This suggests that the calibration process based on world coordinate points that are co-planar (such as the corners of a planar chessboard) can yield accurate results without introducing significant distortions in the wireframe overlay.\n",
    "\n",
    "- Regarding the computed projection matrix, when calibrating based on world coordinate points that are co-planar, the resulting projection matrix is expected to accurately map the 3D world coordinates of the planar object to the 2D image coordinates. Since the points lie on a plane, they can be accurately represented using a homography matrix, which simplifies the calibration process and leads to accurate calibration results.\n",
    "\n",
    "Basically, when we are calibrating a camera using points that are all on the same flat surface (like the corners of a flat chessboard), we can expect the wireframe overlay to not look warped or distorted. Also, the projection matrix that's calculated should accurately show where these 3D points are on the 2D image, which means the calibration should be pretty spot-on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac82e24",
   "metadata": {},
   "source": [
    "### 3. [0.5 points] What is the image of the world origin, given the calibration matrix? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_image(image_path, pixel_coordinates, line_indices, circle_radius=8, circle_color=(0, 255, 0), line_color=(50, 255, 50), line_thickness=5):\n",
    "    \n",
    "    img = cv.imread(image_path)\n",
    "    plt.figure(figsize=(8, 8))  \n",
    "    \n",
    "    # Draw lines between selected points\n",
    "    for start_idx, end_idx in line_indices:\n",
    "        start_point = tuple(map(int, pixel_coordinates[start_idx]))\n",
    "        end_point = tuple(map(int, pixel_coordinates[end_idx]))\n",
    "        cv.line(img, start_point, end_point, line_color, line_thickness)  \n",
    "\n",
    "    # Draw circles at specified pixel coordinates\n",
    "    for idx, point in enumerate(pixel_coordinates):\n",
    "        x, y = map(int, point)\n",
    "        cv.circle(img, (x, y), circle_radius, circle_color, -1)  \n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 7 \n",
    "new_world_origin_coordinates = np.zeros((7*7, 3), np.float32)\n",
    "for i in range(0, grid_size ):\n",
    "    for j in range(0, grid_size ):\n",
    "        new_world_origin_coordinates[(i ) * grid_size + (j)] = [i*2, j*2, 0]\n",
    "        \n",
    "# print(new_world_coordinates)\n",
    "new_origin_line_indices = [(0,42),(1,43),(2,44),(3,45),(4,46),(5,47),(6,48),(0, 6), (7, 13), (14, 20), (21, 27), (28, 34),(35,41),(42,48)]\n",
    "new_origin_wireframes_pixel_coordinates = get_pixel_coordinates(new_projection_matrix, new_world_origin_coordinates)\n",
    "visualize_image(img_new_name, new_origin_wireframes_pixel_coordinates, new_origin_line_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159183c",
   "metadata": {},
   "source": [
    "### Q. Does this result agree with your observations?\n",
    "##### Yes, the result agrees with my  observations\n",
    "\n",
    "The observation was that the wireframe overlay showed minimal distortions and aligned well with the chessboard in the image. \n",
    "\n",
    "By applying from the computed projection matrix to the world origin coordinates (0, 0, 0) we can obtain the image of the world origin.This transformation maps the world origin to its corresponding point on the image plane.\n",
    "\n",
    "When determining the image of the world origin using the calibration matrix, the result aligned with the expectations based on the observations. This alignment confirms that the calibration matrix accurately represents the transformation from 3D world coordinates to 2D image coordinates, consistent with the observed alignment of the wireframe overlay with the actual chessboard in the image. Therefore, the result agrees with the observations made during the calibration process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9970150",
   "metadata": {},
   "source": [
    "# Q3. Moving the Chessboard\n",
    "### 1. Imagine that the chessboard in assign1.jpg was moved by 10 cm to the right (along the ruler). Overlay a wireframe (4 points) of the virtual chessboard on the image at the appropriate location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_moved_world_origin_coordinates = np.array([[0,10,0],[12,10,0],[0,22,0],[12,22,0]])\n",
    "new_moved_line_indices = [(0, 2), (2, 3), (3, 1), (1, 0)]\n",
    "new_moved_wireframes_pixel_coordinates = get_pixel_coordinates(new_projection_matrix, new_moved_world_origin_coordinates)\n",
    "\n",
    "print(new_moved_wireframes_pixel_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_wireframe(img_new_name, new_moved_wireframes_pixel_coordinates, new_moved_line_indices, circle_color=(144, 238, 144), text_color=(128, 128, 128), line_color=(0, 0, 139))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d66a8e7",
   "metadata": {},
   "source": [
    "### Q. -> Does the wireframe look consistent with what you expect?\n",
    "##### Yes, the wireframe looks consistent with what I expect, mostly.\n",
    "\n",
    "Given that the chessboard was moved by 10 cm to the right along the ruler, I would expect the wireframe overlay to reflect this movement by appearing shifted to the right in the image. Since the wireframe was correctly adjusted to accommodate this shift, it appears consistent with what I anticipated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90daabf6",
   "metadata": {},
   "source": [
    "\n",
    "### 2.  Now, think of how you would move the actual pixels or pattern of the chessboard? Overlay the chessboard pattern within the predicted wireframe. Is the overlay consistent with what you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c47dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wireframe Coordinates Before Moving World Origin:\")\n",
    "for idx, point in enumerate(new_wireframes_pixel_coordinates):\n",
    "    print(f\"Point {idx}: ({point[0]}, {point[1]})\")\n",
    "\n",
    "print(\"\\nWireframe Coordinates After Moving World Origin:\")\n",
    "for idx, point in enumerate(new_moved_wireframes_pixel_coordinates):\n",
    "    print(f\"Point {idx}: ({point[0]}, {point[1]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2deb2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_images_side_by_side(original_image, new_image):\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv.cvtColor(original_image, cv.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv.cvtColor(new_image, cv.COLOR_BGR2RGB))\n",
    "    plt.title(\"Image with Adjusted Pixel Values\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_wireframe2(image_path, pixel_coordinates, line_indices, circle_radius=15, circle_color=(0, 255, 0), text_color=(100, 20, 255), line_color=(50, 255, 50), line_thickness=5):\n",
    "    image = image_path\n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    \n",
    "    for start_idx, end_idx in line_indices:\n",
    "        start_point = tuple(map(int, pixel_coordinates[start_idx]))\n",
    "        end_point = tuple(map(int, pixel_coordinates[end_idx]))\n",
    "        cv.line(image, start_point, end_point, line_color, line_thickness)  \n",
    "    \n",
    "    for idx, point in enumerate(pixel_coordinates):\n",
    "        x, y = map(int, point)\n",
    "        cv.circle(image, (x, y), circle_radius, circle_color, -1)  \n",
    "        cv.putText(image, f'{idx}: ({x}, {y})', (x + 5, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2, cv.LINE_AA)\n",
    " \n",
    "    plt.imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c96c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def move_chessboard(original_image, original_coordinates, new_coordinates):\n",
    "    # Convert coordinates to integers\n",
    "    original_coordinates = [(int(x), int(y)) for x, y in original_coordinates]\n",
    "    new_coordinates = [(int(x), int(y)) for x, y in new_coordinates]\n",
    "    \n",
    "    # Create a new image with the same dimensions as the original image\n",
    "    new_image = np.copy(original_image)\n",
    "    \n",
    "    # Extract the region of interest (ROI) from the original image using original coordinates\n",
    "    x_min_original = min(original_coordinates[0][0], original_coordinates[2][0])\n",
    "    x_max_original = max(original_coordinates[2][0], original_coordinates[3][0])\n",
    "    y_min_original = min(original_coordinates[0][1], original_coordinates[2][1])\n",
    "    y_max_original = max(original_coordinates[1][1], original_coordinates[3][1])\n",
    "    print()\n",
    "    # Extract the dimensions of the chessboard ROI\n",
    "    roi_width = x_max_original - x_min_original\n",
    "    roi_height = y_max_original - y_min_original\n",
    "    \n",
    "    # Calculate the displacement between the original and new coordinates\n",
    "    displacement_x = new_coordinates[0][0] - x_min_original\n",
    "    displacement_y = new_coordinates[0][1] - y_min_original\n",
    "    \n",
    "    # Calculate the new position of the top-left corner of the ROI\n",
    "    new_x_min = new_coordinates[0][0]\n",
    "    new_y_min = new_coordinates[0][1]\n",
    "    \n",
    "    # Calculate the new position of the bottom-right corner of the ROI\n",
    "    new_x_max = new_x_min + roi_width\n",
    "    new_y_max = new_y_min + roi_height\n",
    "    \n",
    "    # Paste the ROI onto the new image at the new positions\n",
    "    new_image[new_y_min:new_y_max, new_x_min:new_x_max] = original_image[y_min_original:y_max_original, x_min_original:x_max_original]\n",
    "    \n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_image = cv.imread(\"assign1.jpg\")\n",
    "new_image = move_chessboard(original_image, new_wireframes_pixel_coordinates, new_moved_wireframes_pixel_coordinates)\n",
    "visualize_wireframe2(new_image, new_moved_wireframes_pixel_coordinates, new_moved_line_indices, circle_color=(144, 238, 144), text_color=(128, 128, 128), line_color=(0, 0, 139))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b563f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
